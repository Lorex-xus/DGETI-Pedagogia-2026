{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5+G8IZbsNuQdbA4Ma+Lou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lorex-xus/DGETI-Pedagogia-2026/blob/main/Sesi%C3%B3n%201%20-%20DGETI%20-%20Pedagog%C3%ADa%202026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sesión 1**"
      ],
      "metadata": {
        "id": "Lu0Hki0FD-ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clase itroductoria**: Inteligencia Aritifcial"
      ],
      "metadata": {
        "id": "2Q6Fj9HpZCWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contenido visto en clase"
      ],
      "metadata": {
        "id": "OpOwvHJkZM-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Práctica**"
      ],
      "metadata": {
        "id": "l_fW8oxkEI5s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bab0b5b2"
      },
      "source": [
        "### **Paso 1**: Creando nuestros 'datos de ejemplo'\n",
        "\n",
        "Para entender cómo funciona la clasificación, vamos a crear un conjunto de datos muy simple. Imagina que tenemos dos tipos de flores, representadas por dos características (por ejemplo, el largo y el ancho de sus pétalos). Queremos que una IA aprenda a distinguirlas.\n",
        "\n",
        "Usaremos la librería `scikit-learn` para generar estos datos de manera artificial. Cada punto tendrá dos valores (X e Y) y pertenecerá a una de dos clases (0 o 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d269a9df",
        "outputId": "6de0a0be-5737-4bab-d9c1-58ccd6b77af3"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Generamos 100 puntos de datos con 2 características y 2 clases\n",
        "X, y = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=3)\n",
        "\n",
        "# 'X' son nuestras características (por ejemplo, largo y ancho de pétalo)\n",
        "# 'y' son las etiquetas de las clases (0 o 1)\n",
        "\n",
        "print(f\"Dimensiones de X (características): {X.shape}\")\n",
        "print(f\"Dimensiones de y (etiquetas de clase): {y.shape}\")\n",
        "print(\"Primeros 5 puntos de X:\\n\", X[:5])\n",
        "print(\"Primeras 5 etiquetas de y:\\n\", y[:5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de X (características): (100, 2)\n",
            "Dimensiones de y (etiquetas de clase): (100,)\n",
            "Primeros 5 puntos de X:\n",
            " [[-3.94672034  8.4573092 ]\n",
            " [ 7.88903257  5.13457584]\n",
            " [-4.1423458   9.3470539 ]\n",
            " [ 7.10605932  7.66354863]\n",
            " [ 5.32225864  5.89459795]]\n",
            "Primeras 5 etiquetas de y:\n",
            " [0 1 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "147d21bc"
      },
      "source": [
        "### **Paso 2**: Visualizando nuestros datos\n",
        "\n",
        "Ahora, veamos cómo se ven estos datos. Los graficaremos en un plano 2D, donde cada eje representa una de nuestras características, y el color de cada punto indicará a qué clase pertenece."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48566106"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='viridis', s=100, alpha=0.8)\n",
        "plt.title('Datos de Ejemplo para Clasificación (dos clases)')\n",
        "plt.xlabel('Característica 1')\n",
        "plt.ylabel('Característica 2')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45b5b184"
      },
      "source": [
        "### **Paso 3**: Entrenando un modelo de Clasificación simple\n",
        "\n",
        "Nuestro objetivo es que la IA aprenda a dibujar una línea (o una curva, en casos más complejos) que separe estas dos clases de puntos. Para este ejemplo, usaremos un modelo llamado 'Regresión Logística', que es como una navaja suiza para problemas de clasificación binaria (dos clases) y es fácil de entender.\n",
        "\n",
        "El modelo buscará la mejor 'línea divisoria' que minimice los errores al clasificar los puntos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa0d35a4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Creamos una instancia de nuestro modelo de clasificación\n",
        "model = LogisticRegression(random_state=42)\n",
        "# Random State es una semilla de generación\n",
        "\n",
        "# Entrenamos el modelo con nuestros datos (X) y sus etiquetas (y)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"¡Modelo de clasificación entrenado con éxito!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d898d7"
      },
      "source": [
        "### **Paso 4**: Visualizando la clasificación del modelo\n",
        "\n",
        "Ahora que nuestro modelo ha \"aprendido\", podemos ver cómo ha decidido separar las dos clases. La Regresión Logística, al ser un modelo lineal, dibujará una línea recta en nuestro gráfico 2D. Todo lo que caiga a un lado de la línea se clasificará como una clase, y todo lo que caiga al otro lado, como la otra.\n",
        "\n",
        "También evaluaremos qué tan bien lo hizo, calculando su 'precisión' (accuracy), que nos dice el porcentaje de puntos que clasificó correctamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45566a2d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculamos los límites del gráfico para dibujar la línea de decisión\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                     np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "# Predecimos la clase para cada punto en la 'malla' para pintar el fondo\n",
        "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Pintamos el fondo con las regiones de decisión del modelo\n",
        "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "\n",
        "# Graficamos nuestros puntos de datos originales\n",
        "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='viridis', s=100, alpha=0.8, edgecolor='k')\n",
        "\n",
        "plt.title('Modelo de Clasificación: Regiones y Puntos de Datos')\n",
        "plt.xlabel('Característica 1')\n",
        "plt.ylabel('Característica 2')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# Hacemos predicciones con el modelo para nuestros datos de entrenamiento\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculamos la precisión del modelo\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(f\"\\nLa precisión de nuestro modelo en los datos de entrenamiento es: {accuracy:.2f}\")\n",
        "print(f\"Esto significa que el modelo clasificó correctamente el {accuracy*100:.0f}% de los puntos.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb2b6d1"
      },
      "source": [
        "### **Recapitulando**\n",
        "\n",
        "Hasta el momento actual podemos ver de forma práctia el proceso y pasos para:\n",
        "\n",
        "1.  **Generado** de datos que representan dos categorías.\n",
        "2.  **Visualizado** de esos datos para ver su distribución.\n",
        "3.  **Entrenado** de un modelo de clasificación simple (Regresión Logística).\n",
        "4.  **Visualizado** de cómo el modelo divide el espacio para clasificar nuevos puntos.\n",
        "5.  **Evaluado** el rendimiento con una métrica sencilla.\n",
        "\n",
        "Este es el concepto fundamental detrás de muchos modelos de clasificación en IA: dado un conjunto de características, el modelo aprende a asignar una etiqueta o categoría a nuevos datos basándose en patrones que ha encontrado."
      ]
    }
  ]
}